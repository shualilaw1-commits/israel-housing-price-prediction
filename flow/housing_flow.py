"""
House Price Prediction Flow - ××—×‘×¨ ×‘×™×Ÿ ×¦×•×•×ª ×× ×ª×—×™ ×”× ×ª×•× ×™× ×œ×¦×•×•×ª ××“×¢× ×™ ×”× ×ª×•× ×™×
"""
import os
import json
from dotenv import load_dotenv
from crewai.flow.flow import Flow, listen, start
from pydantic import BaseModel
from typing import Dict, Any

# ×˜×¢×™× ×ª ××©×ª× ×™ ×¡×‘×™×‘×”
load_dotenv()

# ×™×™×‘×•× ×”×¦×•×•×ª×™×
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from crews.data_analyst_crew import DataAnalystCrew
from crews.data_scientist_crew import DataScientistCrew


class FlowState(BaseModel):
    """××¦×‘ ×”-Flow - ×©×•××¨ ××™×“×¢ ×‘×™×Ÿ ×©×œ×‘×™×"""
    dataset_loaded: bool = False
    data_cleaned: bool = False
    eda_completed: bool = False
    features_created: bool = False
    model_trained: bool = False
    evaluation_completed: bool = False

    # × ×ª×™×‘×™× ×œ×§×‘×¦×™×
    clean_data_path: str = ""
    features_path: str = ""
    model_path: str = ""

    # ×ª×•×¦××•×ª
    data_analysis_result: Dict[str, Any] = {}
    modeling_result: Dict[str, Any] = {}


class HousePricePredictionFlow(Flow[FlowState]):
    """
    Flow ××œ× ×œ×—×™×–×•×™ ××—×™×¨×™ ×“×™×¨×•×ª

    ×©×œ×‘×™×:
    1. Data Analyst Crew - × ×™×ª×•×— ×•×—×§×¨ ×”× ×ª×•× ×™×
    2. Validation - ×•×•×œ×™×“×¦×™×” ×©×œ ×”× ×ª×•× ×™×
    3. Data Scientist Crew - ×‘× ×™×™×ª ×•×”×¢×¨×›×ª ××•×“×œ×™×
    """

    @start()
    def start_flow(self):
        """× ×§×•×“×ª ×”×ª×—×œ×” ×©×œ ×”-Flow"""
        print("\n" + "="*60)
        print("ğŸš€ ××ª×—×™×œ Flow ×œ×—×™×–×•×™ ××—×™×¨×™ ×“×™×¨×•×ª")
        print("="*60 + "\n")

        # ××ª×—×•×œ ××¦×‘
        self.state.dataset_loaded = False
        self.state.data_cleaned = False
        self.state.eda_completed = False

        # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª outputs
        os.makedirs("outputs", exist_ok=True)

        return "Data analysis ready to start"

    @listen(start_flow)
    def run_data_analyst_crew(self, message: str):
        """×©×œ×‘ 1: ×”×¨×¦×ª ×¦×•×•×ª ×× ×ª×—×™ ×”× ×ª×•× ×™×"""
        print("\n" + "="*60)
        print("ğŸ“Š ×©×œ×‘ 1: ×¦×•×•×ª ×× ×ª×—×™ ×”× ×ª×•× ×™×")
        print("="*60 + "\n")

        try:
            # ×”×¨×¦×ª ×”×¦×•×•×ª
            analyst_crew = DataAnalystCrew()
            result = analyst_crew.run()

            # ×¢×“×›×•×Ÿ ××¦×‘
            self.state.data_cleaned = True
            self.state.eda_completed = True
            self.state.clean_data_path = "outputs/clean_data.csv"
            self.state.data_analysis_result = result

            print("\nâœ“ ×¦×•×•×ª ×× ×ª×—×™ ×”× ×ª×•× ×™× ×¡×™×™× ×‘×”×¦×œ×—×”!")
            print(f"  - × ×ª×•× ×™× ×× ×•×§×™×: {self.state.clean_data_path}")
            print(f"  - ×ª×•×‘× ×•×ª: outputs/insights.md")
            print(f"  - ×’×¨×¤×™×: outputs/figures/")

            return "Data analysis completed successfully"

        except Exception as e:
            print(f"\nâŒ ×©×’×™××” ×‘×¦×•×•×ª ×× ×ª×—×™ ×”× ×ª×•× ×™×: {str(e)}")
            raise

    @listen(run_data_analyst_crew)
    def validate_data(self, message: str):
        """×©×œ×‘ 2: ×•×•×œ×™×“×¦×™×” ×©×œ ×”× ×ª×•× ×™× ×œ×¤× ×™ ××¢×‘×¨ ×œ×©×œ×‘ ×”×‘×"""
        print("\n" + "="*60)
        print("âœ… ×©×œ×‘ 2: ×•×•×œ×™×“×¦×™×” ×©×œ ×”× ×ª×•× ×™×")
        print("="*60 + "\n")

        # ×‘×“×™×§×” ×©×§×•×‘×¥ ×”× ×ª×•× ×™× ×”×× ×•×§×™× ×§×™×™×
        if not os.path.exists(self.state.clean_data_path):
            raise FileNotFoundError(f"×§×•×‘×¥ × ×ª×•× ×™× ×× ×•×§×™× ×œ× × ××¦×: {self.state.clean_data_path}")

        # ×‘×“×™×§×” ×©×§×•×‘×¥ ×”×—×•×–×” ×§×™×™×
        contract_path = "outputs/dataset_contract.json"
        if not os.path.exists(contract_path):
            raise FileNotFoundError(f"Dataset contract ×œ× × ××¦×: {contract_path}")

        # ×§×¨×™××ª ×”×—×•×–×”
        with open(contract_path, 'r', encoding='utf-8') as f:
            contract = json.load(f)

        # ×‘×“×™×§×•×ª ×•×•×œ×™×“×¦×™×”
        validations = []

        # ×‘×“×™×§×” 1: ×™×© ××¡×¤×™×§ ×©×•×¨×•×ª?
        num_rows = contract.get('cleaning', {}).get('cleaned_rows', 0)
        if num_rows < 1000:
            validations.append(f"âš ï¸  ××–×”×¨×”: ×¨×§ {num_rows} ×©×•×¨×•×ª - ×¤×—×•×ª ××”××™× ×™××•× ×”××•××œ×¥ (1000)")
        else:
            validations.append(f"âœ“ ××¡×¤×¨ ×©×•×¨×•×ª ×ª×§×™×Ÿ: {num_rows:,}")

        # ×‘×“×™×§×” 2: ×™×© ×¢××•×“×ª target?
        columns = contract.get('columns', {})
        if 'Price_Millions' not in columns:
            raise ValueError("×¢××•×“×ª Target (Price_Millions) ×—×¡×¨×”!")
        validations.append("âœ“ ×¢××•×“×ª Target ×§×™×™××ª")

        # ×‘×“×™×§×” 3: ××™×Ÿ ×™×•×ª×¨ ××“×™ ×¢×¨×›×™× ×—×¡×¨×™×?
        missing = contract.get('cleaning', {}).get('missing_values_found', {})
        if missing:
            validations.append(f"âš ï¸  ×–×•×”×• {len(missing)} ×¢××•×“×•×ª ×¢× ×¢×¨×›×™× ×—×¡×¨×™× (×˜×•×¤×œ×•)")
        else:
            validations.append("âœ“ ××™×Ÿ ×¢×¨×›×™× ×—×¡×¨×™×")

        print("×ª×•×¦××•×ª ×•×•×œ×™×“×¦×™×”:")
        for v in validations:
            print(f"  {v}")

        print("\nâœ“ ×•×•×œ×™×“×¦×™×” ×¢×‘×¨×” ×‘×”×¦×œ×—×” - ×××©×™×›×™× ×œ×©×œ×‘ ×”×‘×\n")

        return "Data validation passed"

    @listen(validate_data)
    def run_data_scientist_crew(self, message: str):
        """×©×œ×‘ 3: ×”×¨×¦×ª ×¦×•×•×ª ××“×¢× ×™ ×”× ×ª×•× ×™×"""
        print("\n" + "="*60)
        print("ğŸ¤– ×©×œ×‘ 3: ×¦×•×•×ª ××“×¢× ×™ ×”× ×ª×•× ×™×")
        print("="*60 + "\n")

        try:
            # ×”×¨×¦×ª ×”×¦×•×•×ª
            scientist_crew = DataScientistCrew()
            result = scientist_crew.run()

            # ×¢×“×›×•×Ÿ ××¦×‘
            self.state.features_created = True
            self.state.model_trained = True
            self.state.evaluation_completed = True
            self.state.features_path = "outputs/features.csv"
            self.state.model_path = "outputs/model.pkl"
            self.state.modeling_result = result

            print("\nâœ“ ×¦×•×•×ª ××“×¢× ×™ ×”× ×ª×•× ×™× ×¡×™×™× ×‘×”×¦×œ×—×”!")
            print(f"  - ×¤×™×¦'×¨×™×: {self.state.features_path}")
            print(f"  - ××•×“×œ: {self.state.model_path}")
            print(f"  - ×“×•×— ×”×¢×¨×›×”: outputs/evaluation_report.md")
            print(f"  - Model Card: outputs/model_card.md")

            return "Model training and evaluation completed"

        except Exception as e:
            print(f"\nâŒ ×©×’×™××” ×‘×¦×•×•×ª ××“×¢× ×™ ×”× ×ª×•× ×™×: {str(e)}")
            raise

    @listen(run_data_scientist_crew)
    def finalize_flow(self, message: str):
        """×©×œ×‘ 4: ×¡×™×•× ×”-Flow"""
        print("\n" + "="*60)
        print("ğŸ‰ ×”-Flow ×”×•×©×œ× ×‘×”×¦×œ×—×”!")
        print("="*60 + "\n")

        # ×¡×™×›×•× ×›×œ ×”×ª×•×¦×¨×™×
        outputs = {
            "× ×ª×•× ×™×": [
                "outputs/raw_data.csv",
                "outputs/clean_data.csv",
                "outputs/features.csv"
            ],
            "×ª×™×¢×•×“": [
                "outputs/dataset_contract.json",
                "outputs/insights.md",
                "outputs/feature_engineering_report.md",
                "outputs/evaluation_report.md",
                "outputs/model_card.md"
            ],
            "××•×“×œ×™×": [
                "outputs/model.pkl",
                "outputs/all_models_comparison.json"
            ],
            "×•×™×–×•××œ×™×–×¦×™×•×ª": [
                "outputs/figures/",
                "outputs/evaluation_figures/"
            ]
        }

        print("ğŸ“ ×›×œ ×”×ª×•×¦×¨×™× ×©× ×•×¦×¨×•:\n")
        for category, files in outputs.items():
            print(f"{category}:")
            for file in files:
                exists = "âœ“" if os.path.exists(file) else "âœ—"
                print(f"  {exists} {file}")

        # ×©××™×¨×ª ×¡×™×›×•× ×”-Flow
        flow_summary = {
            "flow_completed": True,
            "timestamp": str(os.path.getctime("outputs")),
            "state": {
                "dataset_loaded": self.state.dataset_loaded,
                "data_cleaned": self.state.data_cleaned,
                "eda_completed": self.state.eda_completed,
                "features_created": self.state.features_created,
                "model_trained": self.state.model_trained,
                "evaluation_completed": self.state.evaluation_completed
            },
            "outputs": outputs
        }

        with open("outputs/flow_summary.json", 'w', encoding='utf-8') as f:
            json.dump(flow_summary, f, ensure_ascii=False, indent=2)

        print("\nâœ“ ×¡×™×›×•× Flow × ×©××¨ ×‘: outputs/flow_summary.json")
        print("\nğŸ¯ ×”×¤×¨×•×™×§×˜ ××•×›×Ÿ! ××¤×©×¨ ×œ×”×¨×™×¥ ××ª ×”-Streamlit dashboard:\n")
        print("   streamlit run app/streamlit_app.py\n")

        return "Flow completed successfully"


def run_flow():
    """×¤×•× ×§×¦×™×” ×¢×–×¨ ×œ×”×¨×¦×ª ×”-Flow"""
    flow = HousePricePredictionFlow()
    result = flow.kickoff()
    return result


if __name__ == "__main__":
    run_flow()
